# Audio-to-Text Playground (with OpenAI Whisper)

A simple **frontend + backend** project written in TypeScript that lets you **record from your microphone** or **upload an audio file** and transcribes it to text using OpenAIâ€™s Whisper model.

---

## âœ¨ Features

- **Web UI**  
  â€“ Single-page interface built with Vite + TypeScript  
  â€“ â€œĞĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒâ€ / â€œĞ¡Ñ‚Ğ¾Ğ¿â€ via MediaRecorder API  
  â€“ â€œĞ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ»â€ via `<input type="file">`  
  â€“ Shared transcript area for both modes
- **Backend API**  
  â€“ Fastify server with `@fastify/multipart` & `@fastify/cors`  
  â€“ `/audio-to-text` endpoint accepts `multipart/form-data`  
  â€“ Uses OpenAI Whisper model via official SDK
- **Networking**  
  â€“ Built-in proxy support (socks-proxy-agent)  
  â€“ CORS enabled for local dev
- **Developer tooling**  
  â€“ TypeScript everywhere  
  â€“ Unit & integration tests with Vitest  
  â€“ Prettier code formatting

---

## Getting Started

You need **two terminals**â€”one for the backend, one for the frontend.

### Backend+Frontend

### 1. Clone the repo

```bash
git clone https://github.com/AnastasiaRokoko/audio-to-text-cli.git
cd audio-to-text-cli

cd backend
npm install
npm run start


cd ../frontend
npm install
npm run dev
# â†’ Vite dev server on http://localhost:5173

```

### 2.ğŸ”§ Tools & Stack

Backend: Node.js, Fastify, @fastify/multipart, @fastify/cors, OpenAI SDK

Frontend: Vite, TypeScript, native DOM API, fetch, MediaRecorder

Shared: Vitest, Prettier

Enjoy building and experimenting with real-time audio transcription! ğŸ™ï¸âœ¨
